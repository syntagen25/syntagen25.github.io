---
layout: home
order: 1
permalink: /
title: About
desc_title: SyntaGen - Harnessing Generative Models for Synthetic Visual Datasets
social: true
---
Computer vision has been rapidly transformed by advancements in generative models, particularly in text-to-image generation with models like Imagen 3, Stable Diffusion 3, Flux, and DALLE-3, as well as text-to-video models such as Sora, Stable Video Diffusion, and Meta MovieGen. In the realm of 3D generation, models like Zero-123, Instant 3D, and the Large Reconstruction Model (LRM) have pushed the boundaries of 3D content creation. These innovations have enabled the development of highly realistic and diverse synthetic visual datasets, complete with annotations and rich variations, which are invaluable for training and evaluating algorithms in object detection, segmentation, representation learning, and scene understanding. The second SyntaGen Workshop aims to foster collaboration and knowledge exchange across the field, bringing together experts and practitioners to propel the development of generative models and synthetic visual datasets to new heights. Through talks, paper presentations, poster sessions, and panel discussions, the workshop will catalyze breakthroughs at the intersection of generative models and computer vision applications.

<div class="content">
  <!-- <p>The field of computer vision has undergone a significant transformation in recent years with the advancement of generative models...</p> -->
  
  <!-- <div class="cta">
      <span class="gift-icon" id="gift-icon">
          <i class="fa fa-gift" aria-hidden="true"></i>
          Attend the SyntaGen Workshop and get our exclusive gifts!
          <i class="fa fa-gift" aria-hidden="true"></i>
      </span>
      <div class="dropdown-content" id="dropdown-content">
          <div class="gift-images">
              <img src="assets/img2/totebag2.png" alt="Gift Tote Bag" class="gift-image">
              <img src="assets/img2/Cap2.png" alt="Gift Cap" class="gift-image">
          </div>
      </div>
  </div> -->

</div>

### **Speakers**

* **TBD**

<!-- <table style="width:100%">
  <tr>
    <td style="text-align:center border-radius:50%">
      <a href="https://www.cs.toronto.edu/~fleet/"><img src="assets/img2/david.jpg" style="border-radius:50%;" height="150" width="150"></a>
    </td>
    <td style="text-align:center">
      <a href="https://web.mit.edu/phillipi/"><img src="assets/img2/philip_isola.jpg" style="border-radius:50%;" height="150" width="150"></a>
    </td>
    <td style="text-align:center">
      <a href="https://jbhuang0604.github.io/"><img src="assets/img2/jinbin2.jpg" height="150" width="150" style="border-radius:50%;"></a>
    </td>
    <td style="text-align:center">
      <a href="https://www.weizmann.ac.il/math/dekel/"><img src="assets/img2/TaliDekel_w4.jpg" height="150" width="150" style="border-radius:50%;"></a>
    </td>
    <td style="text-align:center">
      <a href="https://research.adobe.com/person/nathan-carr/"><img src="assets/img2/nathan.png" height="150" width="150" style="border-radius:50%;"></a>
    </td>
  </tr>
  <tr>
    <td style="text-align:center"><a href="https://www.cs.toronto.edu/~fleet/">David J Fleet</a><br>Professor<br>University of Toronto, Google DeepMind</td>
    <td style="text-align:center"><a href="https://web.mit.edu/phillipi/">Phillip Isola</a><br>Associate Professor<br>MIT</td>
    <td style="text-align:center"><a href="https://jbhuang0604.github.io/">Jia-Bin Huang</a><br>Associate Professor<br>University of Maryland College Park</td>
    <td style="text-align:center"><a href="https://www.weizmann.ac.il/math/dekel/">Tali Dekel</a><br>Assistant Professor<br>Weizmann Institute of Science</td>
    <td style="text-align:center"><a href="https://research.adobe.com/person/nathan-carr/">Nathan Carr</a><br>Adobe Fellow<br>Adobe Research</td>
  </tr>
</table> -->

### **Schedule**

* **TBD**

<!-- | **Time**  | **Event**                                                | **Duration** | **Speaker** |
|-------|------------------------------------------------------|----------|---------|
| 8:25  | Introduction (Gift giveaway)                         | 5 mins   | TBD     |
| 8:30  | Competition session & Winners talks & Oral presentation | 30 mins  | TBD     |
| 9:00  | Invited talk 1                                        | 25 mins  | TBD     |
| 9:25  | Invited talk 2                                        | 25 mins  | TBD     |
| 9:50  | Break (Gift giveaway)                                | 10 mins  | TBD     |
| 10:00 | Invited talk 3                                        | 25 mins  | TBD     |
| 10:25 | Invited talk 4                                        | 25 mins  | TBD     |
| 10:50 | Invited talk 5                                        | 25 mins  | TBD     |
| 11:15 | Panel discussion                                      | 25 mins  | TBD     |
| 11:40 | Poster Session                                        | 40 mins  |      | -->
<!-- <table>
  <thead>
    <tr>
      <th style="text-align:left;">Time</th>
      <th>Event</th>
      <th style="text-align:left;">Duration</th>
      <th style="text-align:left;">Speaker</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align:left;">8:25</td>
      <td>Introduction</td>
      <td style="text-align:left;">5 mins</td>
      <td style="text-align:left;"></td>
    </tr>
    <tr>
      <td style="text-align:left;">8:30</td>
      <td>Competition session & Winners talks & Oral presentation</td>
      <td style="text-align:left;">30 mins</td>
      <td style="text-align:left;"></td>
    </tr>
    <tr>
      <td style="text-align:left;">9:00</td>
      <td>Invited talk 1: Promising Generative Data Augmentation</td>
      <td style="text-align:left;">25 mins</td>
      <td style="text-align:left;"><b>David Fleet</b></td>
    </tr>
    <tr>
      <td style="text-align:left;">9:25</td>
      <td>Invited talk 2: Re-inventing the Factory - the new AI Software Lifecycle</td>
      <td style="text-align:left;">25 mins</td>
      <td style="text-align:left;"><b>Nathan Carr</b></td>
    </tr>
    <tr>
      <td style="text-align:left;">9:50</td>
      <td>Break</td>
      <td style="text-align:left;">10 mins</td>
      <td style="text-align:left;"></td>
    </tr>
    <tr>
      <td style="text-align:left;">10:00</td>
      <td>Invited talk 3: Poor Manâ€™s Guide for Aligned Text-to-Image Synthesis</td>
      <td style="text-align:left;">25 mins</td>
      <td style="text-align:left;"><b>Jia-Bin Huang</b></td>
    </tr>
    <tr>
      <td style="text-align:left;">10:25</td>
      <td>Invited talk 4: N=0: Learning Vision with Zero Visual Data</td>
      <td style="text-align:left;">25 mins</td>
      <td style="text-align:left;"><b>Phillip Isola</b></td>
    </tr>
    <tr>
      <td style="text-align:left;">10:50</td>
      <td>Invited talk 5: The Future of Video Generation: Beyond Data and Scale</td>
      <td style="text-align:left;">25 mins</td>
      <td style="text-align:left;"><b>Tali Dekel</b></td>
    </tr>
    <tr>
      <td style="text-align:left;">11:15</td>
      <td>Panel discussion: Tali Dekel, Phillip Isola, Nathan Carr</td>
      <td style="text-align:left;">25 mins</td>
      <td style="text-align:left;">TBD</td>
    </tr>
    <tr>
      <td style="text-align:left;">11:40</td>
      <td>Poster Session</td>
      <td style="text-align:left;">50 mins</td>
      <td style="text-align:left;"></td>
    </tr>
  </tbody>
</table> -->

### **Accepted Papers**
* TBD 

### **Call for Papers**

#### **Topics**
The main objective of the SyntaGen workshop is to offer a space for researchers, practitioners, and enthusiasts to investigate, converse, and cooperate on the development, use, and potential uses of synthetic visual datasets made from generative models. The workshop will cover various topics, including but not restricted to:
* Leveraging pre-trained generative models to generate data and annotations for perception-driven tasks, including image classification, representation learning, object detection, semantic and instance segmentation, relationship detection, action recognition, object tracking, and 3D shape reconstruction and recognition.
* Extending the generative capacity of large-scale pre-trained text-to-image models to other domains, such as videos, 3D, and 4D spaces.
* Exploring new research directions in generative models, including GANs, VAEs, diffusion models, and autoregressive models, to advance visual content generation.
* Synergizing expansive synthetic datasets with minimally annotated real datasets to enhance model performance across scenarios including unsupervised, semi-supervised, weakly-supervised, and zero-shot/few-shot learning.
* Enhancing data quality and improving synthesis methodologies in the context of pre-trained text-to-image (T2I), text-to-video (T2V), text-to-3D, and text-to-4D models.
* Evaluating the quality and effectiveness of the generated datasets, particularly on metrics, challenges, and open problems related to benchmarking synthetic visual datasets.
* Ethical implications of using synthetic annotated data, strategies for mitigating biases, verifying and protecting generated visual contents, and ensuring responsible data generation and annotation practices.


#### **Important workshop dates**

* TBD

<!-- * Submission deadline: **March 22nd, 11:59 PM Pacific Time**
* Notification of acceptance: **April 7th, 11:59 PM Pacific Time**
* Camera Ready submission deadline: **April 14th, 11:59 PM Pacific Time**
* Workshop date: **June 17th, 2024 (Morning)** -->


### **Organizers**

<table style="width:100%">
  <tr>
    <td style="text-align:center border-radius:50%">
      <a href="https://khoinguyen.org"><img src="assets/img2/org-khoinguyen.jpg" style="border-radius:50%;" height="150" width="150"></a>
    </td>
    <td style="text-align:center">
      <a href="https://scholar.google.com/citations?user=FYZ5ODQAAAAJ&hl=en"><img src="assets/img/org-anh-tran-square.jpg" style="border-radius:50%;" height="150" width="150"></a>
    </td>
    <td style="text-align:center">
      <a href="https://sonhua.github.io/"><img src="assets/img2/org-sonhua.jpg" height="150" width="150" style="border-radius:50%;"></a>
    </td>
    <td style="text-align:center">
      <a href="https://www.supasorn.com/"><img src="assets/img2/org-supasorn.jpg" height="150" width="150" style="border-radius:50%;"></a>
    </td>
    <td style="text-align:center">
      <a href="https://zhouyisjtu.github.io/"><img src="assets/img2/org-yizhou.png" height="150" width="150" style="border-radius:50%;"></a>
    </td>
  </tr>
  <tr>
    <td style="text-align:center"><a href="https://khoinguyen.org">Khoi Nguyen</a> <br>VinAI Research, Vietnam</td>
    <td style="text-align:center"><a href="https://scholar.google.com/citations?user=FYZ5ODQAAAAJ&hl=en">Anh Tuan Tran</a> <br>VinAI Research, Vietnam</td>
    <td style="text-align:center"><a href="https://sonhua.github.io/">Binh Son Hua</a><br>Trinity College Dublin, Ireland</td>
    <td style="text-align:center"><a href="https://www.supasorn.com/">Supasorn Suwajanakorn</a> <br>VISTEC, Thailand</td>
    <td style="text-align:center"><a href="https://zhouyisjtu.github.io/">Yi Zhou</a><br>Adobe</td>
  </tr>
</table>


<!-- ### **Volunteers** -->

<!-- <table style="width:100%">
  <tr>
    <td style="text-align:center">
      <a href="https://truongvu2000nd.github.io/"><img src="assets/img2/truong.jpg" height="150" width="150" style="border-radius:50%;"></a>
    </td>
    <td style="text-align:center">
      <a href="https://quang-ngh.github.io/"><img src="assets/img2/quang.jpg" height="150" width="150" style="border-radius:50%;"></a>
    </td>
  </tr>
  <tr>
    <td style="text-align:center"><a href="https://truongvu2000nd.github.io/">Truong Vu</a><br>Research Resident<br>VinAI Research, Vietnam</td>
    <td style="text-align:center"><a href="https://quang-ngh.github.io/">Quang Nguyen</a><br>Research Resident<br>VinAI Research, Vietnam</td>
  </tr>
</table> -->


### **Organizers affiliations**

<!-- <td style="text-align:center"><a href="https://vinuni.edu.vn/college-of-engineering-computer-science/"><img src="assets/img/inst-vinuni-cecs.png" height="75"></a></td>

<td style="text-align:center"><a href="https://www.cs.umd.edu/"><img src="assets/img/inst-umd-cs.png" height="75"></a></td>
<br>

<td style="text-align:center"><a href="https://www.vinai.io/"><img src="assets/img/inst-vinai.png" height="75"></a></td>
<br>


<td style="text-align:center"><a href="https://www.clemson.edu/index.html"><img src="assets/img/inst-clemson.png" height="75"></a></td>
<br>

<td style="text-align:center"><a href="https://www.deakin.edu.au/"><img src="assets/img/inst-deakin.png" height="75"></a></td>
<br>

<td style="text-align:center"><a href="https://tech.cornell.edu/"><img src="assets/img/inst-cornell-tech.png" height="75"></a></td>
<br>

<td style="text-align:center"><a href="https://www.nyu.edu/"><img src="assets/img/New_York_University-Logo.png" height="75"></a></td> -->

<table style="width:100%; align: left; border: none; spacing: none">
  <tr style="border: none; spacing: none"> 
    <td style="text-align:center; border: none; spacing: none"><a href="https://www.vinai.io/"><img src="assets/img/inst-vinai.png" height="60"></a></td>  
    <td style="text-align:center; border: none; spacing: none"><a href="https://www.tcd.ie/"><img src="assets/img2/aff-tcd.png" height="80"></a></td>
    <td style="text-align:center; border: none; spacing: none"><a href="https://www.vistec.ac.th/"><img src="assets/img2/aff-vistec.jpeg" height="70"></a></td>
    <td style="text-align:center; border: none; spacing: none"><a href="https://research.adobe.com/"><img src="assets/img2/aff-adobe.jpg" height="70"></a></td>
  </tr>
</table> 